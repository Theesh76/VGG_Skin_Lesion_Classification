{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying Skin Lesions using Convolutional Neural Network\n",
    "\n",
    "\n",
    "**Problem Statement:** <br>\n",
    " Train a Neural Network to identify different skin lesions with the given subset of the HAM10000 dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human Against Machine 10000 (HAM10000) Study\n",
    "\n",
    "HAM10000 is a set of 10015 dermatoscopic images which comprises of different pigmented skin lesion. A subset of the HAM10000 dataset is provided to train a neural network to identify the skin lesions. The training and the test set has 997 images, 496 images of pigmented skin lesion respectively. These images belong to seven different pigment skin lesion categories, and they are as follows,\n",
    "\n",
    "1. Actinic keratoses and intraepithelial carcinoma / Bowen's disease - akiec\n",
    "2. basal cell carcinoma - bcc\n",
    "3. benign keratosis-like lesions (solar lentigines / seborrheic keratoses and lichen-planus like keratoses) - bkl\n",
    "4. dermatofibroma -df\n",
    "5. melanoma - mel\n",
    "6. melanocytic nevi - nv \n",
    "7. vascular lesions (angiomas, angiokeratomas, pyogenic granulomas and hemorrhage) - vasc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries used for the assignment is attached below:\n",
    "1. cv2 - Image processing\n",
    "2. json - To read the labels\n",
    "3. matplotlib - To visualize graphs\n",
    "4. sklearn, tensorflow and keras  -  Convolutonal Neural Networks\n",
    "5. json -  To read given labels\n",
    "6. glob -To read all the images in the directory\n",
    "\n",
    "Tensorflow 2.4\n",
    "<br>Python 3.8\n",
    "<br>CUDA Toolkit 11.0\n",
    "<br>CUDNN 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2                \n",
    "import numpy as np             \n",
    "import glob    \n",
    "import json      \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import regularizers\n",
    "from tensorflow.keras.layers import Flatten,Dense,Dropout,BatchNormalization,Conv2D,MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.metrics import Recall\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Lables that needs to be classified: ['akiec' 'bcc' 'bkl' 'df' 'mel' 'nv' 'vasc']\n",
      "The training set comprises of:\n",
      "Actinic Keratoses and IntraEpithelial Carcinoma (akiec) - 30 images\n",
      "Basal Cell Carcinoma (bcc) - 43 images\n",
      "VASCular lesions (vasc) - 97 images\n",
      "DermatoFibroma (df) - 9 images\n",
      "MELanoma (mel) - 82 images\n",
      "melanocytic NeVi (nv) - 723 images\n",
      "VASCular lesions (vasc) - 13 images\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency of Skin Lesions')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('train_labels.json') as f:\n",
    "    data = json.load(f)        \n",
    "data = list(data.items())\n",
    "labels = np.array(data)\n",
    "y = labels[:,1]\n",
    "labels_unique = np.unique(y, axis=0)  \n",
    "print(\"The Lables that needs to be classified:\",labels_unique)\n",
    "with open('train_labels.json') as f:\n",
    "    data = json.load(f)        \n",
    "data = list(data.items())\n",
    "labels = np.array(data)\n",
    "y = labels[:,1]\n",
    "labels, counts = np.unique(y,return_counts=True) \n",
    "ticks = range(len(counts))\n",
    "\n",
    "print(\"The training set comprises of:\")\n",
    "for i in range(len(counts)):\n",
    "    if labels[i] == 'bcc':\n",
    "        print(\"Basal Cell Carcinoma (bcc) -\",counts[i],\"images\")\n",
    "    elif labels[i] == 'akiec':\n",
    "        print(\"Actinic Keratoses and IntraEpithelial Carcinoma (akiec) -\",counts[i],\"images\")\n",
    "    elif labels[i] == 'df':\n",
    "        print(\"DermatoFibroma (df) -\",counts[i],\"images\")\n",
    "    elif labels[i] == 'mel':\n",
    "        print(\"MELanoma (mel) -\",counts[i],\"images\")\n",
    "    elif labels[i] == 'nv':\n",
    "        print(\"melanocytic NeVi (nv) -\",counts[i],\"images\")\n",
    "    else:\n",
    "        print(\"VASCular lesions (vasc) -\",counts[i],\"images\")\n",
    "plt.bar(ticks,counts, align='center')\n",
    "plt.xticks(ticks, labels)\n",
    "plt.title('Data Visulaization of Training Set')\n",
    "plt.xlabel('Different types of Skin Lesions')\n",
    "plt.ylabel('Frequency of Skin Lesions')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following inference can be drawn from the data analysis of the train set.\n",
    "1. There are seven unique labels that needs to be classified. \n",
    "2. The distribution of data among the seven categories is unbalanced.\n",
    "3. It is clearly visible that the label nv comprises 3/4th of the dataset. \n",
    "4. There is less data in the categories df and vasc.\n",
    "5. It is a possiblity that the melanocytic Nevi is the most commonly occuring skin disorder in the humans or it can be also be due to the fact that it is easily detectable skin disorder. Hence, it could be possible reason for data abundance in this particular class.\n",
    "6. A contrast reasoning can be applied for the data class df, vasc for its low number.\n",
    "\n",
    "**Effect of unbalnced data on the Neural network model:**\n",
    "<br>The equal number of data in all the classes is required for training the neural network to perform multi-label classification. However, if the above data is to be used to train a neural network model, the model will fail to classify the labels df,nv especially as it has less data. \n",
    "\n",
    "Methods to overcome the unbalanced data:\n",
    "1. Undersampling -  The data is reduced from the class that has more data in this method. This method makes the model more sensitive to the class that has less data. Eventhough, it helps in improving the multi-class classification accuracy but there is loss of valubale data in the majority class. \n",
    "2. Oversampling - The data is generated for the classes that has low data. It makes the training dataset more balanced. However, the main problem with this method is that it can lead to overfitting the training set. \n",
    " \n",
    "In this assignment, the data is generated to balance the training set. Measures will be taken to prevent the overfitting by using dropouts in the neural network model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation - Data Sorting by Folder\n",
    "The training data is mixed with images of different class. The below code will arrange the images to the corresponding labels in the Data Analysis folder.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "image_paths = glob.glob( 'train/*.jpg' )\n",
    "i=0\n",
    "k1=k2=k3=k4=k5=k6=k7=0\n",
    "for imagefile in image_paths:\n",
    "    image = cv2.imread(imagefile)\n",
    "    if y[i] == 'bcc':\n",
    "        loc = 'Data_Analysis/bcc/' + str(k1) + '.jpg'\n",
    "        cv2.imwrite(loc,image)\n",
    "        k1 = k1 + 1\n",
    "    elif y[i] == 'akiec':\n",
    "        loc = 'Data_Analysis/akiec/' + str(k2) + '.jpg'\n",
    "        cv2.imwrite(loc,image)\n",
    "        k2 = k2 + 1\n",
    "    elif y[i] == 'df':\n",
    "        loc = 'Data_Analysis/df/' + str(k3) + '.jpg'\n",
    "        cv2.imwrite(loc,image)\n",
    "        k3 = k3 + 1\n",
    "    elif y[i] == 'mel':\n",
    "        loc = 'Data_Analysis/mel/' + str(k4) + '.jpg'\n",
    "        cv2.imwrite(loc,image)\n",
    "        k4 = k4 + 1\n",
    "    elif y[i] == 'nv':\n",
    "        loc = 'Data_Analysis/nv/' + str(k5) + '.jpg'\n",
    "        cv2.imwrite(loc,image)\n",
    "        k5 = k5 + 1\n",
    "    elif y[i] == 'bkl':\n",
    "        loc = 'Data_Analysis/bkl/' + str(k6) + '.jpg'\n",
    "        cv2.imwrite(loc,image)\n",
    "        k6 = k6 + 1\n",
    "    else:\n",
    "        loc = 'Data_Analysis/vasc/' + str(k7) + '.jpg'\n",
    "        cv2.imwrite(loc,image)\n",
    "        k7 = k7 + 1\n",
    "    i = i+1    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761552fa",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    " ImageDataGenerator can generate batches of tensor image data. It can modify the original image by\n",
    " 1. rotation_range - How much image can be rotataed\n",
    " 2. shift in the width - 0.05 $\\times$ width of the image - 0.05$\\times$ 600 - 30px max shift allowed \n",
    " 3. shift in the height - 0.05$\\times$ height of the image - 0.05$\\times$ 450 - 22px max shift allowed\n",
    " 4. sheer was not used - shape of moles can cahnge by shear transformation\n",
    " 5. rescale - 1/255 - (0-1) range for LR\n",
    " 6. zoom range - 0.1 Random zooming in the image\n",
    " 7. horizontal_flip - Randomly flipping half of the images horizontally \n",
    " 8. fill_mode - Fills the newly created pixel\n",
    " \n",
    "and can generate a new image. Using this method, many combinations of single image in all the classes were generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b36241",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=10, \n",
    "                               width_shift_range=0.05, \n",
    "                               height_shift_range=0.05, \n",
    "                               rescale=1/255,  \n",
    "                               zoom_range=0.1, \n",
    "                               horizontal_flip=True,\n",
    "                               vertical_flip=True,\n",
    "                               fill_mode='nearest')\n",
    "CATEGORIES = [\"akiec\", \"bcc\", \"bkl\", \"df\", \"mel\", \"nv\", \"vasc\"]\n",
    "label = np.zeros((1,7))\n",
    "for category in CATEGORIES:\n",
    "    image_paths = glob.glob( 'Data_Analysis/'+category+'/*.jpg' )  \n",
    "    for imagefile in image_paths:\n",
    "        image = cv2.imread(imagefile)\n",
    "        x = np.asarray(image)\n",
    "        x = x.reshape((1,) + x.shape)  \n",
    "        i = 0\n",
    "        for batch in datagen.flow(x, batch_size=1,save_to_dir='Data_Analysis/'+category, save_prefix='aug', save_format='jpg'):\n",
    "            if category=='akiec' and i > 25:\n",
    "                break \n",
    "            elif category=='bcc' and i > 15:\n",
    "                break \n",
    "            elif category=='bkl' and i > 6:\n",
    "                break \n",
    "            elif category=='df' and i > 85:\n",
    "                break \n",
    "            elif category=='mel' and i > 7:\n",
    "                break \n",
    "            elif category=='vasc' and i >55:\n",
    "                break \n",
    "            elif category=='nv':\n",
    "                break\n",
    "            else:\n",
    "                i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cc46dc",
   "metadata": {},
   "source": [
    "## Training and Validation data\n",
    "Due to computation complexity, the image data is reduced to 128$\\times$128 pixels. By doing so, the shape of the skin lesion may look different in the training samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b57f6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "y = []\n",
    "CATEGORIES = [\"akiec\", \"bcc\", \"bkl\", \"df\", \"mel\", \"nv\", \"vasc\"]\n",
    "label = np.zeros((1,7))\n",
    "for category in CATEGORIES:\n",
    "    class_num = CATEGORIES.index(category)\n",
    "    label[0,class_num] = 1\n",
    "    image_paths = glob.glob( 'Data_Analysis/'+category+ '/*.jpg' )\n",
    "    for imagefile in image_paths:\n",
    "        img  = cv2.imread(imagefile)\n",
    "        img = cv2.resize(img,(128,128), interpolation = cv2.INTER_LINEAR)\n",
    "        h,w,d = img.shape\n",
    "        img = img/255 # Convert to 0-1 range\n",
    "        images.append(img)\n",
    "        y.append(label)\n",
    "    label = np.zeros((1,7))\n",
    "    \n",
    "x = np.array(images)\n",
    "x1=x.reshape(-1,h,w,d) \n",
    "y = np.array(y)\n",
    "y=y.reshape(len(y),7) \n",
    "train_img,test_img,train_label,test_label = train_test_split(x,y,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8158cd2e",
   "metadata": {},
   "source": [
    "# Convolutional Neural Netwroks\n",
    "A convolutional neural network (CNN) can recognize patterns such as edges (vertical/horizontal), shapes, colours, and textures. Generally, a skin lesions are determined by its size, irregular edges, color, itchiness, location at where it occurs at the body. Drawbacks of using the given set and CNN \n",
    "1. Due to decraese in the resolution of training images, it is susceptible to change in the shape of the skin leasion.  \n",
    "2. Size of the mole cannot be determined by the CNN. The 3rd dimesnion data is missing.\n",
    "3. Data of location of the mole in the body is also missing.\n",
    "\n",
    "Hence, using cnn to classify the given label is challenging and will not be 100% accurate.\n",
    "\n",
    "\n",
    "It is known that when the images go through more layers, the model learns sophisticated patterns. I was restrained from adding more layers to the network given the configuration of my laptop. Dropouts were added to decrease the overfitting of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7498661",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(h,w,d)\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "\n",
    "model.add(Conv2D(64,(2,2),input_shape=input_shape,activation='relu'))\n",
    "model.add(Conv2D(64,(2,2),input_shape=input_shape,activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(Conv2D(128,(2,2),input_shape=input_shape,activation='relu'))\n",
    "model.add(Conv2D(128,(2,2),input_shape=input_shape,activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(256,(2,2),input_shape=input_shape,activation='relu'))\n",
    "model.add(Conv2D(256,(2,2),input_shape=input_shape,activation='relu'))\n",
    "model.add(Conv2D(256,(2,2),input_shape=input_shape,activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(512,(2,2),input_shape=input_shape,activation='relu'))\n",
    "model.add(Conv2D(512,(2,2),input_shape=input_shape,activation='relu'))\n",
    "model.add(Conv2D(512,(2,2),input_shape=input_shape,activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1024,activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64,activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(7,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy',Recall()])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0581a3",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadd37e4",
   "metadata": {},
   "source": [
    "The batch size is 25 becomes of insuffcient memory. Different epochs 50,78 and 500 were taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff7eaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(train_img,train_label,epochs=500,batch_size=25,validation_data=(test_img, test_label))\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.show()\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.legend(['accuracy', 'val_accuracy'])\n",
    "plt.show()\n",
    "model.save( '3_128_128_250.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16328111",
   "metadata": {},
   "source": [
    "There are three model trained \n",
    "1. 2_128_128.h5 - Ran 50 epochs\n",
    "2. 3_128_128_78.h5 - Ran 78 epochs\n",
    "3. 4_128_128_500.h5 - Ran 500 epochs\n",
    "**As the labels of the test data was not given, please try all the models.** The training loss of the 3_128_128_78.h5 and 4_128_128_500.h5 is plotted below.\n",
    "\n",
    "### 3_128_128_78.h5 Model Loss Curve\n",
    "<img src=\"Figure_1.png\">\n",
    "\n",
    "### 4_128_128_500.h5  Model Loss Curve\n",
    "<img src=\"Figure_3.png\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147857bb",
   "metadata": {},
   "source": [
    "## Inference\n",
    " Convert the test images to 128$\\times$128 resolution for inference.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83259dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = []\n",
    "model = load_model('2_128_128.h5')\n",
    "image_paths = glob.glob( 'test/*.jpg' )\n",
    "for imagefile in image_paths:\n",
    "    img  = cv2.imread(imagefile)\n",
    "    img = cv2.resize(img,(128,128), interpolation = cv2.INTER_LINEAR)\n",
    "    img = img/255\n",
    "    np_final = np.expand_dims(img,axis=0)\n",
    "    pred = model.predict(np_final)\n",
    "    index = np.argmax(pred[0,:])\n",
    "    if index == 0:\n",
    "        labs = \"akiec\"\n",
    "    elif index == 1:\n",
    "        labs = \"bcc\"\n",
    "    elif index == 2:\n",
    "        labs = \"bkl\"\n",
    "    elif index == 3:\n",
    "        labs = \"df\"\n",
    "    elif index == 4:\n",
    "        labs = \"mel\"\n",
    "    elif index == 5:\n",
    "        labs = \"nv\"\n",
    "    else:\n",
    "        labs = \"vasc\"\n",
    "    test_labels.append(labs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c3981e",
   "metadata": {},
   "source": [
    "## Future Work - How you would solve this problem if there was more time and computational power?\n",
    "\n",
    "More Time:\n",
    "1. Underfitting - Try training the model by underfitting the data. It is believed that it improves the classification accuracy.\n",
    "2. Do a literature survey if there are other ways to tackle the unbalanced dataset problem.\n",
    "3. As mentioned  before, a comphrehensive study of which architecture to use should be done.\n",
    "4. Data cleaning - Duplicate images were not checked. \n",
    "5. **A detailed study of all skin disorders and its characteristics.**\n",
    "6. Tuning the parameters. \n",
    "\n",
    "More Computation Power:\n",
    "1. Training with deeper neural networks. When the network is deeper, more is the parameter to be trained and the more computation power required.\n",
    "2. Training the neural network with the full image resolution preserving its artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647139fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
